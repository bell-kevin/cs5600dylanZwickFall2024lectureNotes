{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS-6600 Lecture 3 - More Tools of the Trade\n",
        "\n",
        "**Instructor: Dylan Zwick**\n",
        "\n",
        "*Weber State University*\n",
        "\n",
        "References:\n",
        "* [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/) by Aurélien Géron - [Chapter 2: End-to-End Machine Learning Project](https://github.com/ageron/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb)\n",
        "\n",
        "* [Python for Data Analysis](https://wesmckinney.com/book/) by Wes McKinney\n",
        "\n",
        "* [Data Visualization in Python](https://www.amazon.com/Data-Visualization-Python-Pandas-Matplotlib/dp/B0972TFYN8) by David Landup (Full course [here](https://stackabuse.com/courses/data-visualization-in-python-with-matplotlib-and-pandas/))"
      ],
      "metadata": {
        "id": "SI2EVDOR9tCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "  <img src=\"https://imgs.xkcd.com/comics/real_estate_analysis.png\" alt=\"xkcd planetary analysis\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "ZaWU1HnrN5SS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our last class I tried to cover an intro to Jupyter notebooks, NumPy, and Pandas all in one 75 minute class. I was not successful. Specifically, we made it through Jupyter notebooks and NumPy, but didn't even start with Pandas.\n",
        "\n",
        "So, today we'll do a bit of catching up and finish the material on Pandas. We'll also try to cover some basic data visualization in Python.\n",
        "\n",
        "Next week, we'll get going on data science and modeling.\n"
      ],
      "metadata": {
        "id": "gfBRBBc8-0Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I mentioned last time my style is to usually import the libraries I need right at the start of the notebook. Let's do that here. The first three libraries we import are ones we'll be using *all the time*, and so you'll see them at the top of pretty much every notebook from now on."
      ],
      "metadata": {
        "id": "UJ5zds16E5w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joke - How do you ruin a data scientist's day?\n",
        "\n",
        "```\n",
        "import numpy as pd\n",
        "import pandas as np\n",
        "```"
      ],
      "metadata": {
        "id": "QK5E7FcRFWt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do it right and import them with the standard abbreviations. As with NumPy and \"np\", almost always the name of the library \"pandas\" is abbreviated as \"pd\" when it's imported, and pd is used to reference it afterwards."
      ],
      "metadata": {
        "id": "m0RRMCuLFYBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd #This is the way.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib.patches import Circle\n",
        "from matplotlib.patheffects import withStroke\n",
        "from matplotlib.ticker import AutoMinorLocator, MultipleLocator"
      ],
      "metadata": {
        "id": "ATTHmZqLFLrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Pandas Library"
      ],
      "metadata": {
        "id": "jg6-yyiqS5wJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a078e87b-984f-41ae-ba17-cf9146f65200"
      },
      "source": [
        "Along with NumPy, the other great workhorse library for data science with Python is *pandas*. As with NumPy, we will not cover, or even come close to covering, the entire library today. Also, there are many aspects and facets of Pandas that you'll learn and internalize only by using it. However, today should - ideally - give you a starting point.\n",
        "\n",
        "A note on nomenclature. The name \"Pandas\" did not originate as a reference to the deceptively cute type of bear, but as an abbrevation and amalgamation of \"Panel Data\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7743bcd-2e67-45a0-bf29-4fcf98634178"
      },
      "source": [
        "### Pandas Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e04d40c-fc34-4bfe-8553-cd61ad64f8cf"
      },
      "source": [
        "The dataset with which we'll play around is the \"royal line\" dataset, which was created from public sources and contains family history information about Elizabeth II, the Queen of England at the time the dataset was compiled. Note a few things about the command below:\n",
        "\n",
        "* It uses the read_csv command from pandas, which is used to read in \"comma separated value\" files. This is a very common format for storing tabular data, as it's not tied to a particular program like, for example, Excel files are. However, Pandas also has functionality for reading in pretty much any type of data format commonly found in practice.\n",
        "\n",
        "* The basic data object in Pandas is a \"dataframe\", which is created by the read_csv command. Frequently, a dataframe is denoted with the abbreviation \"df\", which we do here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/uc?export=download&id=1k7k-ObAKWhW0iPbyCplogGMGsy29Mif5' #This URL points to the royal_line.csv file stored on my (Dylan's) Google Drive. You should all be able to access it."
      ],
      "metadata": {
        "id": "h_v4pnx4ZWAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b654ef4-d06d-47ad-b29b-dba2d6ee568a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ddf6766-0af1-4058-acd1-e16db226f438"
      },
      "source": [
        "We can then take a look at this dataframe using the \"print\" command, which will by default print the first five and last five rows of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b6e2f3e-0326-469d-9080-0ac13057e3a3"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "379d6271-ef99-4c6a-ba8d-64383f2242d8"
      },
      "source": [
        "If we just want to check out the first $n$ values, we can use the \"head\" function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5a2ce89-8c3a-4b2b-b92a-2ad06f43c401"
      },
      "outputs": [],
      "source": [
        "print(df.head())\n",
        "print(df.head(12))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bb24c84-99be-4ca5-8157-8474886bbd8c"
      },
      "source": [
        "And similarly the \"tail\" function returns the last $n$ values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f91fcc5-8337-44dd-8e00-6ce4db819a4e"
      },
      "outputs": [],
      "source": [
        "print(df.tail(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "273a2b8f-b570-4f61-930d-0263965e1672"
      },
      "source": [
        "You may have noticed in the printed dataframe an additional column of numbers located to the far left of the data. For instance, if we just call df.head() with the default option (which is 5), we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0a8352-6670-4ebe-ad85-5536b69abf5b"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff14535b-8db7-4c1d-abf2-380701c522ad"
      },
      "source": [
        "That first column is an index column created by Pandas for the dataframe. It starts at $0$ and enumerates from there. Note this column is *not* in our original csv - it's created.\n",
        "\n",
        "In this example, our original csv already has an index column, called ID, that starts at 1, so this additional data column is a bit redundant. We can specify an index column when we read in the data using the \"index_col\" parameter in read_csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ee6711-e489-48e2-b700-bc7a9793c25e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f0a2622-a410-4209-bba4-cb49be58f5ea"
      },
      "source": [
        "Now, the index column is the \"ID\" column from the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3885c260-c613-4cef-8db0-bf622d854868"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ff3cb33-06f0-40ee-af16-6e2ff34eeeba"
      },
      "source": [
        "If we only wanted to see the \"title\" column, we could do so as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "050dff20-40c8-4317-9043-fd6ba84678d7"
      },
      "outputs": [],
      "source": [
        "df['title'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e730a088-78be-414b-af2a-5cbc266ba35b"
      },
      "source": [
        "We can specify more than one column in this way as well. Note the *double brackets*. Think of this as the outer brackets accessing the dataframe, while the inner brackets specify a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75790c6e-3620-44e3-8c43-7e63a7a82f46"
      },
      "outputs": [],
      "source": [
        "df[['title', 'first_name']].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae2c04ae-80b7-42cc-9745-9c4aca791d15"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de4b6432-1c34-483e-91eb-8d93e8bad22d"
      },
      "source": [
        "Note this returns an index object that behaves as an iterable list, so you could, for example, go through the colums with a for loop.\n",
        "\n",
        "You can also find out more information about a dataframe using the \"info\" function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1feccfe-818e-4173-a22c-d8092847f337"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fca811-b1f7-4292-8e32-d7c49210dbb4"
      },
      "source": [
        "### Dropping or Removing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95012357-e987-480b-bd9c-05ba496f2f49"
      },
      "source": [
        "There are many reasons why you might want to drop or remove data from a dataframe. For example, it could be that only some data is relevant to your analysis. Or, it could be that some data is insufficient or corrupt, and leaving it in would lead to incorrect conclusions. Also, sometimes certain columns aren't of interest to the analysis in question.\n",
        "\n",
        "If we want to drop entire columns, we can use the \"drop\" function and specify the columns as a list in the argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c889c77e-8d6b-498c-81d9-bcf4afc6a645"
      },
      "outputs": [],
      "source": [
        "df.drop(columns = ['birth_place', 'death_place'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26609b10-405b-4a64-a22b-d81485ea2945"
      },
      "source": [
        "However, while the dataframe above only has six columns, if we call it again we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0427866-039b-4527-a97d-467b26455230"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "120c0217-59de-422b-a0bd-e302e1a18290"
      },
      "source": [
        "What?!? I thought we dropped two!\n",
        "\n",
        "What's going on here is that the drop command creates a new dataframe as its output. It *does not* modify the original dataframe. So, for example, we could say:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52a96faf-0653-47df-8731-925e03e5bad0"
      },
      "outputs": [],
      "source": [
        "df2 = df.drop(columns = ['birth_place', 'death_place'])\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fa429fd-7949-4936-9189-8851c7cf101d"
      },
      "source": [
        "Here, df2 is the dataframe with those two columns dropped, while df is the original, unchanged dataframe.\n",
        "\n",
        "If we want to actually make the change to the original dataframe, we can do this with the \"inplace\" argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63878a6b-6510-4670-a470-4698ded367b7"
      },
      "outputs": [],
      "source": [
        "df.drop(columns = ['birth_place', 'death_place'], inplace = True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bad50605-58d4-4919-b5f3-3fe0a0867b0d"
      },
      "source": [
        "This is the same as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9cdc1af-5344-4053-973b-ef661396ba8c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "df = df.drop(columns = ['birth_place', 'death_place'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac04471-232d-4520-a7f0-af886a0e3a52"
      },
      "source": [
        "You can also drop rows by indicating specific indices with the *index* argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0560e109-79dc-40a2-8897-27e21484bf24"
      },
      "outputs": [],
      "source": [
        "df.drop(index=[4,5,6], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb81377b-eb4e-4269-ae7a-1cf3c695a505"
      },
      "source": [
        "Or, by using df.index, which avoids potential variations in index numbering and always references the first row starting with $0$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab3a1093-1d93-4bcf-bf7c-85b0c455df45"
      },
      "outputs": [],
      "source": [
        "df.drop(df.index[0], inplace=True)\n",
        "df.drop(df.index[0], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6596fb-e520-4697-a1cc-698369089d7b"
      },
      "source": [
        "Each line drops the first row on the dataframe, whatever that first row might be. So, these two lines together drop the first two rows. We can also use standard Python indexing and slicing notation to specify indices here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d9d056d-9a35-4480-8343-db04bb8d0f27"
      },
      "outputs": [],
      "source": [
        "df.drop(df.index[2:5], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79d096b8-66c3-4a78-85f2-feaf0ec09f48"
      },
      "source": [
        "The \"drop_duplicates\" function can be used to drop duplicate rows, while the \"dropna\" function drops every row that includes at least one NA entry. Be careful with this one, as it could potentially drop a lot of rows!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcb8ea07-b205-4564-a4a2-2e85646cd2d3"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df555446-a12d-4742-b757-863d6c37d731"
      },
      "source": [
        "### Adding, Modifying Data, and Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea77d54b-881c-4084-a32a-c7873bd85629"
      },
      "source": [
        "Suppose we have a dataframe with NA values, and instead of dropping them we want to fill them with some values we determine. Here are a few ways to do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e853119-f6cc-4023-80f9-b3276e16c3ea"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# replace ALL NA entries with a fixed value:\n",
        "df.fillna(0, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80ae1393-f72e-4225-8976-2744678cd036"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# replace the first 2 NA entries in each column with a fixed value:\n",
        "df.fillna(0, limit=2, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02bc6a29-05f3-4943-a8c1-8b7bb193e1bc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# replace ALL NA first names with a fixed value:\n",
        "df['first_name'].fillna('no first name', inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0d4c834-1b68-49a0-afc1-b679de106fb8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# replace specific columns with specific values provided by a dictionary:\n",
        "values = {'first_name': 'no_first_name', 'last_name': 'no_last_name', 'sex': 'no_sex', 'title': 'no_title', 'birth_date': 'no_birth_date', 'birth_place': 'no_birth_place', 'death_date': 'no_death_date', 'death_place': 'no_death_place'}\n",
        "df.fillna(value=values, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3723f77a-c590-4b09-8498-d93e1943aac3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# ffill and pad: from first row to last row, propagate the most recent row that is not an NA forward until next valid row\n",
        "df.ffill(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ce784cd-1220-49fb-914d-27e9db304852"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "# bfill and backfill: like ffill, except from last row to first row\n",
        "df.bfill(inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcadf24b-fc15-4385-893e-ca66818332e0"
      },
      "source": [
        "We can also create new columns from existing ones. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c470389-3fb9-411c-b7e8-25bb09899a13"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "df['full_name'] = df['first_name'] + ' ' + df['last_name']\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25f4479a-72d6-4984-9b65-9c55063c130a"
      },
      "source": [
        "This illustrates a problem. Anytime we have an NaN value, the string concatenation is also NaN. How could we get around this? Well, we could create our own specific function that handles this, and then apply that to our dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabbdfde-574e-43de-831a-75d37fe41f1a"
      },
      "outputs": [],
      "source": [
        "def create_full_name(row):\n",
        "    if isinstance(row['first_name'], str) and isinstance(row['last_name'], str):  # both first_name and last_name are strings\n",
        "        result = row['first_name'] + ' ' + row['last_name']\n",
        "    elif isinstance(row['first_name'], str):  # only first_name is a string\n",
        "        result = row['first_name']\n",
        "    elif isinstance(row['last_name'], str):  # only last_name is a string\n",
        "        result = row['last_name']\n",
        "    else:  # neither first_name nor last_name are strings, they are both NaN\n",
        "        result = np.nan\n",
        "    return result\n",
        "\n",
        "df = pd.read_csv(url, index_col='ID')\n",
        "\n",
        "df['full_name'] = df.apply(create_full_name, axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ca2580-8a6b-41fb-a0ad-fd7f0e5f0197"
      },
      "source": [
        "This \"apply\" operation applies the specified function. You could also use Python lambda functions to create a function inline if needed. Note the option \"axis = 1\" means to process the data row by row. The option \"axis = 0\" would process the data column by column. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b0b2f46-361c-43a6-8591-ed30eba26290"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe that is a 6 x 2 array formed from a list of 12 numbers ordered from 0 to 11.\n",
        "df = pd.DataFrame(np.arange(12).reshape(6,2), columns = ['column 1', 'column 2'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61e299f2-6c20-44ce-af30-b83df2157fe3"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe that takes the maximum value of each column in the dataframe we just created.\n",
        "new_df = df.apply(lambda column: column.max())\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cb14ac9-b8df-4817-a825-5f9a19066ae4"
      },
      "source": [
        "There are three main functions used to create or change data in dataframes: apply, map, and applymap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee2931ae-fe6c-4ab3-8f56-c5390f757710"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(np.arange(8).reshape(4,2), columns = ['column 1', 'column 2'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *apply* function can be used to apply a function along either axis of a dataframe."
      ],
      "metadata": {
        "id": "6aWVXYC9mpuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a98b426-d1c2-49ed-8f0d-2df4483c439a"
      },
      "outputs": [],
      "source": [
        "print(df.apply(np.max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2795f539-800e-4238-971c-abb0815db548"
      },
      "outputs": [],
      "source": [
        "print(df.apply(np.max, axis = 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *map* function is a bit more limited and is used to apply a function element-wise to a series. It's more efficient than *apply* when used in this way."
      ],
      "metadata": {
        "id": "wifC8UrqnOGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6eb233d-6efd-4314-80ce-6e60bb115f64"
      },
      "outputs": [],
      "source": [
        "print(df['column 1'].map(lambda x: x*2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *applymap* function is used for element-wise operations across all elements of a dataframe, not just those within a series."
      ],
      "metadata": {
        "id": "E1iXflLpnmAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e537aba3-5649-4c76-acac-ee3f84925a50"
      },
      "outputs": [],
      "source": [
        "print(df.applymap(lambda x: x*2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f30070a0-2f01-47c4-b09e-efa38cae0b24"
      },
      "source": [
        "### Changing Datatypes of Series or Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a6ccb6d-271c-472f-ad09-f3178205d482"
      },
      "source": [
        "The datatypes for our \"royal_line\" examples have all been 'objects' because every column has had data that's been interpreted as a string. This is a general, default datatype that is quite encompassing in what it can handle. However, there are some functions, like maximum or average, that make sense for certain types of numeric data, but not for general data, and if we try to apply these functions to objects we'll have a bad time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "519bd940-bb43-496e-9f59-93bb695c1781"
      },
      "outputs": [],
      "source": [
        "# Let's create a simple dataframe with three columns containing different types of data:\n",
        "df = pd.DataFrame({'ints': [1,2,3,4], 'strings': ['a','b','c','d'], 'floats': [1.1, '2.2', '3.3', 4]})\n",
        "print(df)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ddf3da-b2c2-4790-ad49-b9b4c130554b"
      },
      "source": [
        "Here, the second and third column are interpreted as objects because both contained strings (the values 2.2 and 3.3 in the floats column were entered as strings).\n",
        "\n",
        "To convert these to a different datatype, we can convert a single column, or multiple columns using a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6890b9c-8178-41f2-a7b7-f65ecb49e628"
      },
      "outputs": [],
      "source": [
        "df['floats'] = df['floats'].astype(float)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9820c35-2fcc-4fa0-9aeb-743764cd1788"
      },
      "outputs": [],
      "source": [
        "convert_dict = {'ints': int, 'strings': str, 'floats': float}\n",
        "df = df.astype(convert_dict)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcc7104e-5a9f-40cf-8ebf-a9ce40238615"
      },
      "outputs": [],
      "source": [
        "# The following command would also work:\n",
        "df['ints'] = df['ints'].astype(float)\n",
        "print(df)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbab0f98-2c1e-471e-964a-d02203de8274"
      },
      "outputs": [],
      "source": [
        "# But this one won't:\n",
        "df['strings'] = df['strings'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4aec381-2539-4374-b675-d0045e17dcc8"
      },
      "source": [
        "Pandas has many built in conversion functions (to_datetime, to_timedelta, to_numeric, etc...) but you'll sometimes encounter data that's formatted in such a way that it's not possible to immediately convert it to the format you want using one of the built in functions. To deal with this, sometimes you need to write your own conversion function.\n",
        "\n",
        "For example, if we check out the 'birth_date' column in our royal_line dataset, we see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a4138d8-46a4-4961-88be-4f7c9781b43c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "print(df['birth_date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cfcde0c-8970-49bd-8e7d-5a735401d8c9"
      },
      "source": [
        "A lot of NaN. OK, let's remove these and see what we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4e45386-b275-46b0-a55a-e323db423f0f"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset = ['birth_date'], inplace=True)\n",
        "print(df['birth_date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c80ea057-3a0b-4270-b162-963690201063"
      },
      "source": [
        "If we then try to convert these values to datetimes we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fd6623b-8a79-4db1-9c3c-5b800cb85921"
      },
      "outputs": [],
      "source": [
        "df['birth_date'] = pd.to_datetime(df['birth_date']) # This fails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf58be3-7345-426b-b6da-4eb4122babc0"
      },
      "source": [
        "This generates errors due to several issues.\n",
        "\n",
        "First, there are entries in the dataset formatted like the following: ABT 751. This notation means that the family history experts believe the person was born about (ABT) 751.\n",
        "\n",
        "The second is an out of bounds nanosecond timestamp error related to Pandas only supporting approximately 580 years in the range from around 1677 to 2262.\n",
        "\n",
        "To get around these issue, we'll write and then apply our own function. Note we're not dropping the NaN values here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9331569f-e76a-4627-b28a-606d939f178e"
      },
      "outputs": [],
      "source": [
        "def get_year(x):\n",
        "    if pd.isna(x):\n",
        "        year_result = np.nan  # if the birth_year is nan then return nan\n",
        "    else:  # checking a number of edge cases in the data and stripping it out:\n",
        "        if \"ABT\" in x:  # for example: ABT  1775\n",
        "            x = x[3:]\n",
        "            x = x.strip()\n",
        "        if \"/\" in x:  #  For example: 1775/1776\n",
        "            x = x[:x.find('/')]\n",
        "        num_spaces = x.count(' ')\n",
        "        if num_spaces == 0:  # only has the year\n",
        "            year_result = int(x)\n",
        "        elif num_spaces == 1:  # example: FEB 1337\n",
        "            x = x[x.rfind(' ') + 1:]  # 'rfind' finds the last space. The 'r' stands for 'reverse.'\n",
        "            if x.isnumeric():\n",
        "                year_result = int(x)\n",
        "            else:  # This could happen if there is only a day and month, like '10 JAN'\n",
        "                year_result = np.nan\n",
        "        elif num_spaces == 2:  # example: 16 FEB 1337\n",
        "            x = x[x.rfind(' ') + 1:]\n",
        "            year_result = int(x)\n",
        "        else:\n",
        "            year_result = np.nan  # There are a few other strange dates that aren't worth our time to fix, so just return nan for those.\n",
        "    return year_result\n",
        "\n",
        "df['birth_year'] = df['birth_date'].map(get_year)\n",
        "\n",
        "print(df['birth_year'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9874cbe-98da-43cc-b683-cceda54e2f25"
      },
      "source": [
        "### Conditionals in Dataframes and Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83ad58c-ddd0-45de-af0e-0ab6d4fc4364"
      },
      "source": [
        "Conditionals are a very useful feature of Pandas which typically produce a Numpy array of Booleans or a Pandas Boolean series.\n",
        "\n",
        "For example, consider the following code that produces True if the birth_year column (calculated above) is greater than or equal to 1990, and False otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f284c3f3-44e5-4c02-9092-8358591fade5"
      },
      "outputs": [],
      "source": [
        "boolean_mask = (df.birth_year >= 1990)\n",
        "print(boolean_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "887524ad-cfb3-408b-8721-7809cd4aeca5"
      },
      "source": [
        "We can then use this to, for example, only print the entries for which the boolean is True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d98cbd8-ecf1-42c8-96a8-c6d29f810a9f"
      },
      "outputs": [],
      "source": [
        "print(df[boolean_mask][['first_name', 'last_name', 'birth_year']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b27ad5f-eba7-48f9-9269-c3aa268db111"
      },
      "source": [
        "We can combine Boolean expressions using the logical operators & (\"and\"), | (\"or\"), and ~ (\"not\"). For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5072497e-b16f-4209-a9bc-099a1b35c4e2"
      },
      "outputs": [],
      "source": [
        "print(df[(df.birth_year >= 1500) & (df.title.str.contains('Queen'))][['first_name', 'title', 'birth_year']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65223f3d-26df-42bb-8b37-2739eff4496a"
      },
      "source": [
        "### loc and iloc Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d28ffab-caaf-40a5-85a7-e018097f79c0"
      },
      "source": [
        "One of the most common tasks for data scientists is filtering information to more efficiently derive actionable insights. Marketers also like saying things like that.\n",
        "\n",
        "We've seen the \"head\" and \"tail\" functions, which provide a quick, truncated view of the beginning or end, respectively, of the dataframe or series. But what if you're interested in examining results that are not necessarily at the very beginning or end of the dataset.\n",
        "\n",
        "For this purpose, the loc function is designed to access rows and columns by label. In contrast, the iloc function is used to access rows and columns by integer value - the \"i\" stands for \"integer\".\n",
        "\n",
        "A quick example of the difference is illustrated below, where both commands do the same thing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "319b2da6-b061-463b-afb1-d7cccfee40e2"
      },
      "outputs": [],
      "source": [
        "print(df.loc[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0379c05-3a0b-4a9b-acb2-2b681e5857ff"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77b533f4-7b8d-4319-97a4-34bb363c199c"
      },
      "source": [
        "However, the following will produce an error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f968edf-6c88-4025-bea2-9fb153afe95f"
      },
      "outputs": [],
      "source": [
        "print(df.loc[0]) #This fails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7089a36e-0975-444a-aabc-681345bbef34"
      },
      "source": [
        "Because there is no row with label 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ae7c61-e041-4945-ad75-48878aa18397"
      },
      "source": [
        "Now, row indices (labels) don't need to be unique. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d795d66a-7d1f-482d-b87f-d2c78476913b"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(np.arange(10).reshape(5, 2), columns=['A', 'B'], index=['cat', 42, 'stone', 42, 12345])# Five rows each with an associated index\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bea90b54-d3e1-423c-8e15-cfab251fa88a"
      },
      "source": [
        "The index \"42\" appears twice, and some indices are numbers, while some are strings. Let's look at some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faa1ed1f-4f5e-4e39-8e62-585e58953c8a"
      },
      "outputs": [],
      "source": [
        "print(df.loc[12345])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b357af6-dc91-4acb-a3c6-fb2d1c282a2a"
      },
      "outputs": [],
      "source": [
        "print(df.loc['stone'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d39c236-b1c2-4d71-8f0d-a205a3def9eb"
      },
      "outputs": [],
      "source": [
        "print(df.loc[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0068e31a-5b7d-4ea0-9aa6-810a06aed3c2"
      },
      "outputs": [],
      "source": [
        "print(df.loc['A']) #This will fail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "461c326d-edc3-4dfc-aa94-54b1b132e103"
      },
      "outputs": [],
      "source": [
        "print(df.loc['cat':'stone'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bcaea12-7f75-4970-989c-fe66aa2d9908"
      },
      "outputs": [],
      "source": [
        "print(df.loc[['cat','stone']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "854ce347-18c8-443a-bbb3-b0a463cedcc8"
      },
      "outputs": [],
      "source": [
        "print(df.loc['stone', 'B'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "067bf67c-561e-459b-ba9e-0954304eba0a"
      },
      "outputs": [],
      "source": [
        "print(df.loc[df['A'] > 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bc6b9cd-fa6b-415b-91f1-46fc6e92c75f"
      },
      "source": [
        "Now let's take a look at some iloc examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92ecf740-998a-4b97-a835-a461717302ff"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7600da8f-87ee-46ca-99b8-4134c018f206"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3ae548e-b769-4039-9067-79c1464fcace"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[[0,2,4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "113c4b23-4641-4a76-b630-f895968eec0e"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84851fa7-8695-4926-a0b7-331af4f42aad"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0:3,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7543b0-2786-4e49-aee5-36d664874643"
      },
      "source": [
        "Returning to the royal family history data as an example, let's create a new column named \"era\". The \"era\" column signifies if a person was born in one of three distinct time periods: 'ancient', 'middle_years', or 'modern'. The following creates a new column and initially assigns the value 'unknown' to every entry within it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d81bf457-469b-472d-9be9-ece9a9584b25"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "df['birth_year'] = df['birth_date'].map(get_year)\n",
        "df['era'] = 'unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "167a9716-28bd-439a-bdee-90a03282eb00"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "327c8a9a-a070-45c3-90a9-13460be2f0ea"
      },
      "source": [
        "The next question is how to divide the birth years. If we check out their maximum and minimum values, we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "573260ad-ff91-4ad9-b27a-76d98fbcdce3"
      },
      "outputs": [],
      "source": [
        "print(f\"The earliest year = {df['birth_year'].min()} and the latest year = {df['birth_year'].max()}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94cfa7ed-5d78-47f7-aeca-67e63ac771d8"
      },
      "source": [
        "So, 686 is the earliest year, and 1991 is the latest. This is a difference of 1991 - 656 = 1305 years, which if we divide by 3 this gives us 435 years per era. So, the \"ancient\" royals are those born between 686 and 1121, the \"middle_years\" royals are those born between 1121 and 1555, and the \"modern\" royals are those born after 1555. (Not all that modern!) We can assign these three eras with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0068ddf2-0f86-467c-8296-cd4f80d92c25"
      },
      "outputs": [],
      "source": [
        "df.loc[df['birth_year'] < 1122, 'era'] = 'ancient'  # 686 – 1121\n",
        "df.loc[(df['birth_year'] >= 1122) & (df['birth_year'] <= 1555), 'era'] = 'middle_years'  # 1122 – 1555\n",
        "df.loc[df['birth_year'] > 1555, 'era'] = 'modern'  # after 1555\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ceba278-db49-45b1-897f-b6086da1a254"
      },
      "source": [
        "We could have also done this using a custom function and the \"map\" utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5cb2f42-9cd2-4ee3-acd7-6a256a071696"
      },
      "source": [
        "### Reshaping with Pivot, Pivot_Table, Groupby, and Transpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756b6461-07b4-4d8d-bdff-8929618869ff"
      },
      "source": [
        "Frequently it is convenient or informative to restructure data contained in a dataframe, effectively organizing the data into a different shape or format. This section will cover the most common reshaping functions provided by Pandas.\n",
        "\n",
        "The pivot function addresses the situation in which separate categories of a dataset feature are enumerated and highlighted using a cross tabular format. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ace91f6c-37ad-4512-8a51-cb58c106ceb9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'Car': [1, 1, 2, 2],\n",
        "                   'Type': ['new', 'used', 'new', 'used'],\n",
        "                   'Price': [10, 5, 12, 7]})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd19ee9b-3c66-4c23-9d6c-d3c293de8123"
      },
      "source": [
        "Calling the pivot function on this dataframe will reword the data into a more compact and usable format. In the example above, we want to reshape the data such that each car brand is represented on a single row. A use case for this particular reorganization would be a car salesperson who needs to quickly view all the prices of a given car brand for the different 'Type' categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef132774-64d0-451a-95aa-2163987debe3"
      },
      "outputs": [],
      "source": [
        "p = df.pivot(index='Car', columns='Type', values='Price')\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868611f7-6fb4-44ce-9abe-d5f717601e49"
      },
      "source": [
        "The pivot function only works if there is either zero or one entries per cell in the result. Suppose we have the following dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9306a1d9-6a6e-4080-881d-1e282a42242e"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'Car': [1, 1, 2, 2, 2],\n",
        "                   'Type': ['new', 'used', 'new', 'used', 'used'],\n",
        "                   'Price': [10, 5, 12, 7, 6]})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3ceb0a4-6648-44db-a401-a2dbde89ef59"
      },
      "source": [
        "Invoking the pivot function on this dataframe will generate an error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4447587-e73d-41a9-8099-a200cecf99e6"
      },
      "outputs": [],
      "source": [
        "p = df.pivot(index='Car', columns='Type', values='Price') #This will fail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81e495e-a25a-42c8-8d12-58c37a69a80a"
      },
      "source": [
        "The reason for this is there are two price entries for the used version of car 2. In this case what we could do is use the \"pivot_table\" function with an aggregator, which specifies how to combine values when more than 1 occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38956dc7-1293-4af9-b72d-a6bd2cf4342a"
      },
      "outputs": [],
      "source": [
        "p = df.pivot_table(index='Car', columns='Type', values='Price', aggfunc=np.mean)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3637a44-ff6f-43ac-8c48-df8d561f37a1"
      },
      "source": [
        "Pivot tables can result in immensely complex tabular formats with multiple indexes, multiple columns, and various aggregation functions specified. Today, we demonstrate only the basic single-index, single-column case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec939a61-a9a6-491f-b1db-b9fbdb7d3c49"
      },
      "source": [
        "Here's another example of a pivot_table using our royal family history dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eac1a6b0-526c-4b45-8618-cbb610625c93"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url, index_col='ID')\n",
        "df['birth_year'] = df['birth_date'].map(get_year)\n",
        "\n",
        "df.dropna(inplace=True, subset=['title', 'sex', 'birth_year'])\n",
        "p = df.pivot_table(index='title', columns='sex', values='birth_year', aggfunc='mean')\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66a2aedc-a075-4c95-8716-bca21ed7542a"
      },
      "source": [
        "Here are two more examples. The first fills blank entries in the resulting pivot table after aggregation with $0$ instead of NaN, and uses two aggregate functions, mean and count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0701ade-9595-40f7-ada7-a730a5191edd"
      },
      "outputs": [],
      "source": [
        "p = df.pivot_table(index='title', columns='sex', values='birth_year', aggfunc=['mean', 'count'], fill_value=0)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff160ec-5473-4f0a-bf31-798f6908b3f3"
      },
      "source": [
        "The second is similar to the first, but instead declares two indexes and two columns producing a much more complicated, nested output result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c2e14b5-7f09-4aa5-8cf9-ec225eb8dec5"
      },
      "outputs": [],
      "source": [
        "p = df.pivot_table(index=['title', 'first_name'], columns=['sex', 'last_name'], values='birth_year', aggfunc=['mean', 'count'], fill_value=0)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bde3f764-e02d-4289-9267-b22b7b3b8e57"
      },
      "source": [
        "The groupby function's recasting of information is very similar to that of the pivot_table function. In general, the main difference is how the resulting output is shaped. Note it's a common mistake to create a group object without specifying an aggregating function like mean, sum, or std.\n",
        "\n",
        "Consider the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14213b7b-daca-4e93-88d5-83ed7b150bad"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'Car': [1, 1, 2, 2, 2],\n",
        "                   'Type': ['new', 'used', 'new', 'used', 'used'],\n",
        "                   'Price': [10, 5, 12, 7, 6]})\n",
        "\n",
        "g = df.groupby(by='Car')\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "441819a3-b014-41d2-a386-b51f7ddf12ae"
      },
      "source": [
        "That's not particularly helpful. However, if we group by 'Car' and invoke the 'mean' function, we obtain a more useful result."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = df.groupby(by='Car').mean() #Thil will fail\n",
        "print(g)"
      ],
      "metadata": {
        "id": "VijbcPQn_7fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whoa! What happened there? Well, it's trying to apply the aggregate function to both the price, which is fine, and the type, which is not. This used to result in a warning and dropping the type column, but in more recent versions of Pandas it gives an error.\n",
        "\n",
        "How can we get around this? Well, we can drop the *Type* column first."
      ],
      "metadata": {
        "id": "AA977Hde_-an"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978c04b3-45a2-4598-accd-618b31a1917a"
      },
      "outputs": [],
      "source": [
        "g = df[['Car','Price']].groupby(by='Car').mean() #Need to toss out the \"Type\" column, or it will try to take its mean.\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74dec7c6-a91d-42c5-ab9f-d22fafc62598"
      },
      "source": [
        "If instead of mean we wanted to use the more robust count we don't need to toss out the type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65f9fd99-6504-4e9f-9223-b000ccf94118"
      },
      "outputs": [],
      "source": [
        "g = df.groupby(by='Car').count()\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b2ea6ce-11cd-4fda-b0d2-ed70b2d5f6f0"
      },
      "source": [
        "If we wanted to group by both 'Car' and 'Type', and use two different aggregation function, we could do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb46c83a-9d69-4fcf-b7e0-a671fc187c28"
      },
      "outputs": [],
      "source": [
        "g = df.groupby(by=['Car','Type']).agg(['mean','count'])\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "418f6c3e-0347-4dfb-99ab-8a1785f16809"
      },
      "source": [
        "Finally, and with NumPy arrays, the transpose function (or simply T) transposes a dataframe. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2814ac4-c10f-4c0f-8f1b-af8aca43ae2c"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(np.arange(6).reshape(3, 2), columns=['A', 'B'])\n",
        "print(f'Original\\n{df}')\n",
        "\n",
        "df = df.transpose()  # or df.T\n",
        "\n",
        "print(f'\\nTransposed:\\n{df}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matplotlib and Pyplot"
      ],
      "metadata": {
        "id": "rl6eyI50aR-t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ea4e3f-241e-451b-8b11-6b310d4e35d1"
      },
      "source": [
        "Matplotlib is the JavaScript of Python.\n",
        "\n",
        "I'll explain what I mean. It's a tool that was built with a fairly limited purpose for a relatively small audience, that has then grown far beyond the vision of its creators, and its current version is a amazing amalgam built upon a flimsy foundation.\n",
        "\n",
        "Most notably, matplotlib was originally built to try to mirror the functionality and structure of the data visualization tools in MATLAB. This made a lot of sense 20 years ago, but is certainly not something that would be a goal if you were trying to build a data visualization tool in Python from scratch today. A fun and interesting article about its history and issues can be found [here](https://ryxcommar.com/2020/04/11/why-you-hate-matplotlib/).\n",
        "\n",
        "So, if you find yourself struggling with matplotlib, don't beat yourself up. However, the most important thing to know about matplotlib is that it's widely used, and if you're doing data visualization in Python, for better or worse it's the foundation for everything, and you'll need to understand it.\n",
        "\n",
        "\"There are only two kinds of languages: the ones people complain about and the ones nobody uses\". - [Bjarne Stroustrup](https://www.youtube.com/watch?v=JBjjnqG0BP8) (Inventor of C++)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5642625f-b86a-4b24-bf6a-5336b07f491c"
      },
      "source": [
        "OK, now that's out of the way, let's look at some of the basic visualization capabilities in matplotlib. First, we'll typically not import matplotlib per se, but rather pyplot, which is a collection of functions that make matplotlib work like MATLAB. We'll be using pyplot so frequently that from now on it will be joining the pantheon of libraries that we import at the start of everything we do, and which we always abbreviate according to convention.\n",
        "\n",
        "This is done at the start of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Plotting Paradigm"
      ],
      "metadata": {
        "id": "_n0Mz3yacQLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5a43ed7-8818-40eb-82f3-85f4847d93de"
      },
      "source": [
        "The paradigm we're working with in pyplot is essentially that all our functions are altering a figure, and this changes the figure's *state*. The state is saved and carried across function calls so calling multiple functions will essentially build on top of the state left from the previous functions.\n",
        "\n",
        "For example, calling *plt.plot()* multiple times will plot multiple plots on top of each other, after which you can *plt.show()* them. Let's construct a simple line plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ded6083a-7a59-4db7-a0b8-d09c38699380"
      },
      "outputs": [],
      "source": [
        "x = [1,2,3,4,5]\n",
        "y = [1,4,5,7,2]\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ac24cd-49c2-414f-8e34-9027703e9e26"
      },
      "source": [
        "Nice.\n",
        "\n",
        "OK, let's do this again, but this time with two plots containing the same values on the horizontal ($x$) axis, but different values on the vertical ($y$) axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b17705b-b24e-4d3c-be26-878ab51d19d7"
      },
      "outputs": [],
      "source": [
        "x = [1,2,3,4,5]\n",
        "y = [1,4,5,7,2]\n",
        "z = [1,6,2,5,1]\n",
        "plt.plot(x,y)\n",
        "plt.plot(x,z)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "684a8dfa-3d0b-4980-a966-3e339fe66341"
      },
      "source": [
        "We've now got two plots displayed within the same figure, and along the same x-axis.\n",
        "\n",
        "OK, what if we have not just different y-axis values, but different x-axis values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f5c875e-bb11-4b30-9284-4a429d292f61"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = [6,7,8,9,15]\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8c20e70-32f3-4f27-a760-2a75f3f0e6ea"
      },
      "source": [
        "Nice.\n",
        "\n",
        "The x-axis adjusts its size to accommodate both x-value inputs.\n",
        "\n",
        "But, what happens if no such sensible accommodation can be made. For example, we're not just restricted to having numeric values on our x-axis. We can have categorical ones as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c819167-f893-4713-8482-1e3242dcad07"
      },
      "outputs": [],
      "source": [
        "x = ['a','b','c','d','e']\n",
        "y = [1,6,2,5,1]\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ae12a97-2035-4377-8c53-19670b9562a4"
      },
      "source": [
        "What happens if we combine this and a plot with numeric x-values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecc181e4-0932-42bf-a50f-1de4cbc94133"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = ['a','b','c','d','e']\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d590be92-4c4f-45a2-886f-43c106f7b2df"
      },
      "source": [
        "It does its best. It displays on the x-axis the most recent set of x-values that make sense, and tries to interpret earlier x-values appropriately. In this case, it associates the value x = 1 with the index 1 categorical term.\n",
        "\n",
        "The important thing to note is that matplotlib really *tries* here. It doesn't just throw an error and say what you gave it doesn't make sense. Whether this behavior is good or bad is a matter of debate, but that's what it does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ce44e7-adbf-451c-911e-3f832ca1a694"
      },
      "source": [
        "The plots above defaulted to line graphs using default colors. These defaults are not in any way mandatory, and can be modified. Like, a lot.\n",
        "\n",
        "For example, if instead of the above we coded this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6402975d-92f1-42f0-b783-8da049cb8c12"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = ['a','b','c','d','e']\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2, 'ro')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1efa859f-8ec8-4052-81a7-e001834a8fc9"
      },
      "source": [
        "What's going on here? Well, when we specified 'ro' in the plot command, this specified:\n",
        "\n",
        "* 'r' - Color (r is red, g is green, b is blue, ...)\n",
        "* 'o' - Shape (o is circle,, - is line, ...)\n",
        "\n",
        "If instead we wanted green \"x\" marks, we could do that too!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5ac05c8-66e2-47a3-baa4-c666e0695d4f"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = ['a','b','c','d','e']\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2, 'gx')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3061f7-e9e6-4b0d-98a2-1d796a6a1cba"
      },
      "source": [
        "A list of the matplotlib markers and their corresponding terms can be found [here](https://matplotlib.org/stable/api/markers_api.html). A list of matplotlib colors and their corresponding terms can be found [here](https://matplotlib.org/stable/gallery/color/named_colors.html). Have fun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c554dcba-af78-4eae-86ec-693543ff9a16"
      },
      "source": [
        "The marks and colors are not by any means the only things we can customize. We could, for example, add labels to our axes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7e3a7c7-69ca-453f-b858-c71b08a5fa00"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = ['a','b','c','d','e']\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2, 'gx')\n",
        "plt.ylabel('Y-Axis Label')\n",
        "plt.xlabel('X-Axis Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65fdde71-2181-4ed0-9b97-3caa81834293"
      },
      "source": [
        "This is all very nice for quick, simple plots. We can write just a few lines of code and have a working visualization, letting matplotlib auto-configure the elements of the plot for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2814145-65ff-47e3-bb10-2ae421ab436e"
      },
      "source": [
        "Now, this functional style approach we've used so far comes from matplotlib's MATLAB antecedents. It's what we'll use for most of the class, but it should be noted that there are also more object-oriented approaches to using matplotlib - particularly regarding \"getter\" and \"setter\" functions. We'll demonstrate a few of these here, although we'll mostly stick with the functional paradigm. But keep in mind that essentially everything we'll do under the functional paradigm has an object-oriented parallel and vice-versa. These two approaches do exactly the same thing, just with different commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1e35558-d14c-45a2-881f-589b63988a98"
      },
      "source": [
        "If we wanted to recreate our first plot using a more object-oriented approach, we could do so with the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb32079e-080a-459e-8925-1190818591fb"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure()\n",
        "ax = figure.add_axes([0,0,1,1])\n",
        "\n",
        "x = [1,2,3,4,5]\n",
        "y = [1,7,3,9,3]\n",
        "\n",
        "ax.plot(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cce4e2bd-d974-4a30-a27b-f5d001d62940"
      },
      "source": [
        "We'll get into the details of this in a bit, but first, let's talk about the objects. What are the objects in a plot? Well, the good folks at matplotlib generated a wonderful figure that points out many of the objects, and even provided the code for creating it! Check it out below (don't worry about understanding the code right now)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33605cc3-e945-4e4a-9190-1020ab4a3aa5"
      },
      "outputs": [],
      "source": [
        "royal_blue = [0, 20/256, 82/256]\n",
        "\n",
        "\n",
        "# make the figure\n",
        "\n",
        "np.random.seed(24601) #Anybody get the reference?\n",
        "\n",
        "X = np.linspace(0.5, 3.5, 100)\n",
        "Y1 = 3+np.cos(X)\n",
        "Y2 = 1+np.cos(1+X/0.75)/2\n",
        "Y3 = np.random.uniform(Y1, Y2, len(X))\n",
        "\n",
        "fig = plt.figure(figsize=(7.5, 7.5))\n",
        "ax = fig.add_axes([0.2, 0.17, 0.68, 0.7], aspect=1)\n",
        "\n",
        "ax.xaxis.set_major_locator(MultipleLocator(1.000))\n",
        "ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
        "ax.yaxis.set_major_locator(MultipleLocator(1.000))\n",
        "ax.yaxis.set_minor_locator(AutoMinorLocator(4))\n",
        "ax.xaxis.set_minor_formatter(\"{x:.2f}\")\n",
        "\n",
        "ax.set_xlim(0, 4)\n",
        "ax.set_ylim(0, 4)\n",
        "\n",
        "ax.tick_params(which='major', width=1.0, length=10, labelsize=14)\n",
        "ax.tick_params(which='minor', width=1.0, length=5, labelsize=10,\n",
        "               labelcolor='0.25')\n",
        "\n",
        "ax.grid(linestyle=\"--\", linewidth=0.5, color='.25', zorder=-10)\n",
        "\n",
        "ax.plot(X, Y1, c='C0', lw=2.5, label=\"Blue signal\", zorder=10)\n",
        "ax.plot(X, Y2, c='C1', lw=2.5, label=\"Orange signal\")\n",
        "ax.plot(X[::3], Y3[::3], linewidth=0, markersize=9,\n",
        "        marker='s', markerfacecolor='none', markeredgecolor='C4',\n",
        "        markeredgewidth=2.5)\n",
        "\n",
        "ax.set_title(\"Anatomy of a figure\", fontsize=20, verticalalignment='bottom')\n",
        "ax.set_xlabel(\"x Axis label\", fontsize=14)\n",
        "ax.set_ylabel(\"y Axis label\", fontsize=14)\n",
        "ax.legend(loc=\"upper right\", fontsize=14)\n",
        "\n",
        "\n",
        "# Annotate the figure\n",
        "\n",
        "def annotate(x, y, text, code):\n",
        "    # Circle marker\n",
        "    c = Circle((x, y), radius=0.15, clip_on=False, zorder=10, linewidth=2.5,\n",
        "               edgecolor=royal_blue + [0.6], facecolor='none',\n",
        "               path_effects=[withStroke(linewidth=7, foreground='white')])\n",
        "    ax.add_artist(c)\n",
        "\n",
        "    # use path_effects as a background for the texts\n",
        "    # draw the path_effects and the colored text separately so that the\n",
        "    # path_effects cannot clip other texts\n",
        "    for path_effects in [[withStroke(linewidth=7, foreground='white')], []]:\n",
        "        color = 'white' if path_effects else royal_blue\n",
        "        ax.text(x, y-0.2, text, zorder=100,\n",
        "                ha='center', va='top', weight='bold', color=color,\n",
        "                style='italic', fontfamily='monospace',\n",
        "                path_effects=path_effects)\n",
        "\n",
        "        color = 'white' if path_effects else 'black'\n",
        "        ax.text(x, y-0.33, code, zorder=100,\n",
        "                ha='center', va='top', weight='normal', color=color,\n",
        "                fontfamily='monospace', fontsize='medium',\n",
        "                path_effects=path_effects)\n",
        "\n",
        "\n",
        "annotate(3.5, -0.13, \"Minor tick label\", \"ax.xaxis.set_minor_formatter\")\n",
        "annotate(-0.03, 1.0, \"Major tick\", \"ax.yaxis.set_major_locator\")\n",
        "annotate(0.00, 3.75, \"Minor tick\", \"ax.yaxis.set_minor_locator\")\n",
        "annotate(-0.15, 3.00, \"Major tick label\", \"ax.yaxis.set_major_formatter\")\n",
        "annotate(1.68, -0.39, \"xlabel\", \"ax.set_xlabel\")\n",
        "annotate(-0.38, 1.67, \"ylabel\", \"ax.set_ylabel\")\n",
        "annotate(1.52, 4.15, \"Title\", \"ax.set_title\")\n",
        "annotate(1.75, 2.80, \"Line\", \"ax.plot\")\n",
        "annotate(2.25, 1.54, \"Markers\", \"ax.scatter\")\n",
        "annotate(3.00, 3.00, \"Grid\", \"ax.grid\")\n",
        "annotate(3.60, 3.58, \"Legend\", \"ax.legend\")\n",
        "annotate(2.5, 0.55, \"Axes\", \"fig.subplots\")\n",
        "annotate(4, 4.5, \"Figure\", \"plt.figure\")\n",
        "annotate(0.65, 0.01, \"x Axis\", \"ax.xaxis\")\n",
        "annotate(0, 0.36, \"y Axis\", \"ax.yaxis\")\n",
        "annotate(4.0, 0.7, \"Spine\", \"ax.spines\")\n",
        "\n",
        "# frame around figure\n",
        "fig.patch.set(linewidth=4, edgecolor='0.5')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0702bd2c-c49c-45a1-a590-83d0cdc49b28"
      },
      "source": [
        "* **Figure** - The figure contains *everything* that we'll be seeing within it. Each *Figure* object can have one or more *Axes* objects.\n",
        "* **Axes** - Although the name *Axes* implies the actual axes of the plot, the *Axes* object can practically be seen as *the plot itself*. An *Axes* sits snug in the *Figure* and contains elements such as *Titles, Legends, Grids, etc.* Since a *Figure* can have multiple *Axes* objects, each would actually be a plot for itself. Keep in mind that in the previous example, where we've used *plot()* two times, we haven't created multiple *Axes* objects. Both of these lines were plotted on the same *Axes* object, as *plot* doesn't create a plot, it, well, plots.\n",
        "* **Title** - The title of the *Axes* object.\n",
        "* **Legend** - The legend of the *Axes* object.\n",
        "* **Ticks** - Sub-divided into *major ticks* and *minor ticks*. These are the ticks on the X-axis and Y-axis we've seen in the examples above.\n",
        "* **Labels** - Labels can be set for the X and Y-axis, or for ticks. They're used to, well, label certain elements of the plot for a finer user experience.\n",
        "* **Grids** - Optional lines in the background of the plot, that help the viewer to distinguish between similar X and Y values, based on the frequency of grid lines.\n",
        "* **Lines / Markers** - The actual lines / markers that are used to express records / data of a plot. Most of the time, you'll use lines to plot continuous data, while you'll use markers for discrete data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3676e5ca-9cfa-4b6d-b825-d1390e0e4fee"
      },
      "source": [
        "Alright, as mentioned in the plots we've constructed so far we've only had one *Axes* object, even though we've placed multiple plots upon those axes. Suppose that instead of wanting to plot everything on one axes, we want to use multiple axes, but stay within the same figure. How might we do this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce091276-877e-4bb0-9ec8-d640aa308120"
      },
      "source": [
        "Well, one way to do this is by using the add_subplot function. This creates an 'axes' object on a *grid* with the specified row, column, and index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26c0471-e25a-4246-b92c-48dfa813e3e8"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure()\n",
        "ax = figure.add_subplot(1,1,1)\n",
        "\n",
        "x = [1,2,3,4,5]\n",
        "y = [1,7,3,9,3]\n",
        "\n",
        "ax.plot(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10392a1d-023e-4c14-a6a4-419d5ead42f6"
      },
      "source": [
        "If we set this to the (1,2,2) position instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4f136f8-6a0e-4c85-93c2-a3160563d64f"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure()\n",
        "ax1 = figure.add_subplot(1,2,1)\n",
        "ax2 = figure.add_subplot(1,2,2)\n",
        "\n",
        "x = [1,2,3,4,5]\n",
        "y = [1,7,3,9,3]\n",
        "z = [1,6,2,4,5]\n",
        "\n",
        "ax1.plot(x,y)\n",
        "ax2.plot(x,z)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edfcc347-5e24-4553-afa3-b5c81df46048"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "x = [1,2,3,4,5]\n",
        "y = [1,7,3,9,3]\n",
        "\n",
        "ax.plot(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7ea159d-fb55-407e-964c-eaaaddb271f2"
      },
      "source": [
        "If we'd like to work with more than one subplot, we simply specify the number of them in *subplots()*. Let's create 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "197bd9e1-b127-4521-87ec-5038ee0ce1e3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(4)\n",
        "\n",
        "x = [5,4,2,6,2]\n",
        "y = [1,7,3,9,3]\n",
        "z = [1,6,2,4,5]\n",
        "n = [7,3,2,5,2]\n",
        "\n",
        "ax[0].plot(x)\n",
        "ax[1].plot(y)\n",
        "ax[2].plot(z)\n",
        "ax[3].plot(n)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a509f55-e7e9-43b1-9497-1f764c5fafd3"
      },
      "source": [
        "This creates four different *Axes* and plots them on different rows in the same column. We can also create them as separate objects with unique references, instead of as four objects in a Numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c62ca30-b126-4245-a913-9ed61a288fa4"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4)\n",
        "\n",
        "ax1.plot(x)\n",
        "ax2.plot(y)\n",
        "ax3.plot(z)\n",
        "ax4.plot(n)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2700aabd-6532-42c8-84e5-5b2d175031cf"
      },
      "source": [
        "Creating these 4 plots is a bit of a squeeze for the default figure size. However, all of this is customizable, which we'll now go into in a bit more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97e72107-3825-42b9-9f84-d256b6fb2c08"
      },
      "source": [
        "### Basic Matplotlib Customization ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1db6096-271b-4163-94bd-e836a0308f5b"
      },
      "source": [
        "A good portion of matplotlib's popularity comes from its customizability.\n",
        "\n",
        "There's a ton that can be customized, and a ton of options for customization. We won't and can't go over all of them. Instead, we'll explore a few common operations, such as changing the figure and the font size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d2de05e-c22c-4d12-9894-e97c6b85d0a5"
      },
      "source": [
        "Going back to our plot above, we note it's squeezed and it doesn't look good. Let's change the figure size to allow all four of these *Axes* objects to fit nicely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d9c0478-87a7-4cc1-9613-511191c7e875"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize=(6,8))\n",
        "\n",
        "ax1.plot(x)\n",
        "ax2.plot(y)\n",
        "ax3.plot(z)\n",
        "ax4.plot(n)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfeb6a03-ec94-4cde-96cc-09dd3ed0d328"
      },
      "source": [
        "This created a figure object that's 6 inches by 8 inches.\n",
        "\n",
        "Instead of using the *figsize* argument, we can also set the height and width of a  figure. These can be done either via the *set()* function with the *figheight* and *figwidth* argument, or via the *set_figheight()* and *set_figwidth()* functions. Many ways to do the same thing. Let's see some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0285b53-7c72-4817-8a40-670be3bc7425"
      },
      "outputs": [],
      "source": [
        "#Example using the set() function\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "fig.set(figheight = 5, figwidth = 10)\n",
        "\n",
        "# Adds subplot on index 1\n",
        "ax1 = fig.add_subplot(121)\n",
        "# Add subplot on index 2\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.plot(x,y)\n",
        "ax2.plot(x,z)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2a923d-ba6a-4892-80a2-e130d8b2c0fe"
      },
      "outputs": [],
      "source": [
        "#Example using the set_figheight() and set_figwidth() functions.\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "fig.set_figheight(5)\n",
        "fig.set_figwidth(10)\n",
        "\n",
        "# Adds subplot on index 1\n",
        "ax1 = fig.add_subplot(121)\n",
        "# Add subplot on index 2\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.plot(x,y)\n",
        "ax2.plot(x,z)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83a1397-e882-4ebd-989b-0cded3944fb6"
      },
      "source": [
        "We can also use the *set_size_inches()* of the Figure object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6f0edd3-dda7-4ea2-9428-f07a4d4a49b1"
      },
      "outputs": [],
      "source": [
        "#Example using the set_size_inches() function.\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "fig.set_size_inches(10,5)\n",
        "\n",
        "# Adds subplot on index 1\n",
        "ax1 = fig.add_subplot(121)\n",
        "# Add subplot on index 2\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.plot(x,y)\n",
        "ax2.plot(x,z)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a603fb1-4b68-4069-84d4-4c66ac1fe45d"
      },
      "source": [
        "Please note there's no right or wrong approach here - matplotlib allows you to customize the figures in many ways, because it's anticipated you might want to change the parameters in many ways. Also, because it wasn't planned out very well, and the community has just kept adding different ways to do the same thing aligned with different structural goals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90c2312a-2ed6-4803-a703-bcdf90363e6f"
      },
      "source": [
        "Now let's talk a bit about text. Adding text to plots is a very common task. This text could be labels for axes, titles for plots, or even values of certain markers in the form of tooltips. We use text to give further context to the numerical and visual data on the plots.\n",
        "\n",
        "One of the key classes here, unsurprisingly, in the *Text* class, which takes care of the parsing, storing, and drawing of textual data on plots, given certain coordinates. All the methods we'll use to add labels, titles, etc. rely on the functionality of this class.\n",
        "\n",
        "For example, we we called:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c757c84-4916-46c1-ae0c-958138de40d1"
      },
      "outputs": [],
      "source": [
        "x_1 = [1,2,3,4,5]\n",
        "y_1 = [1,4,5,7,2]\n",
        "x_2 = ['a','b','c','d','e']\n",
        "y_2 = [1,6,2,5,1]\n",
        "plt.plot(x_1,y_1)\n",
        "plt.plot(x_2,y_2, 'gx')\n",
        "plt.ylabel('Y-Axis Label')\n",
        "plt.xlabel('X-Axis Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "947b9d7e-f327-4718-ac43-7d9d0bee7810"
      },
      "source": [
        "The \"xlabel\" and \"ylabel\" functions constructed *Text* instances with default parameters. We'll rarely work manually with *Text* instances. Most of the time we'll be using helper functions that construct instances and assign them to appropriate positions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4c00cb5-73af-49bc-98a0-cd1aca717911"
      },
      "source": [
        "Let's create a plot with some text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d52023f9-6594-4fc8-ad14-02e2a167dc1a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "fig.suptitle('This is the Figure-level Subtitle')\n",
        "ax.set_title('This is the Axes-level Title')\n",
        "ax.set_xlabel('X-label')\n",
        "ax.set_ylabel('Y-label')\n",
        "ax.text(0.5,0.5, 'This is generic text')\n",
        "ax.annotate('This is an annotation, with an arrow between \\n itself and generic text',\n",
        "            xy = (0.625, 0.5),\n",
        "            xytext = (0.25,0.25),\n",
        "            arrowprops=dict(arrowstyle='<->',\n",
        "                            connectionstyle='arc3, rad=0.15'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "566d982a-0779-49bc-8efa-2fe135bdf947"
      },
      "source": [
        "The *suptitle()* is added at the Figure-level, and is above all of its subplots. The *title* and labels can be set on the Axes-level, where each *Axes* can have separate titles and labels.\n",
        "\n",
        "We did use the generic *text()* here. The *x* and *y* values refer to *actual* values on the plot - not percentages. By default, matplotlib creates a 1x1 plot, so in this case our text starts at the very center.\n",
        "\n",
        "Finally, regarding the *annotate()* method, the *xy* tuple is the endpoint of the annotation - to where it's pointing, the *xytext* is the position of the text. The *arrowprops* accepts a dictionary with various properties you can use to customize the arrows. You can find details about the various options [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.annotate.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e535d30-3a0c-4445-a7ad-e46c61a27e64"
      },
      "source": [
        "Annotations are not the only way to provide observers with a way to differentiate and interpret the data on the plot. We commonly color-code certain variables, so they can easily be differentiated with a simple glance. You can add annotations for these - the green line is the age variable, the red line is the population variable, etc., but this can become unwieldy. Also, it's a bit weird to annotate features. Annotations are typically used to point out certain observations.\n",
        "\n",
        "To point out features, we typically use a legend, which could have, for example, a list of colors and a list of labels for these colors.\n",
        "\n",
        "Let's first create a simple plot with two variables, each with a different color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baf24434-ec07-433f-9623-f8a27176aabf"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue')\n",
        "ax.plot(z, color = 'black')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36afbd25-423a-4a2e-885a-944e425674cb"
      },
      "source": [
        "Next, let's add a legend to this plot. First, we'll want to label our variables so we can refer to them in the legend. Once this is done, all we need to do is call the legend() function on the *Axes* instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd51c248-b76e-4418-8c61-eb22cb96cc6a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1358351-a9c6-4419-81db-439905ab6263"
      },
      "source": [
        "Matplotlib does its best to fit the legend in a place where it'll obstruct the least of the plot.\n",
        "\n",
        "But, suppose we don't like where the legend has been placed. Let's place it somewhere else. Specifically, let's place it in the top-right corner, and let's remove the border."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14796ccc-2d73-4789-a5b9-375ac02df835"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(loc='upper right', frameon=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e725780-0dcc-4fff-bfd4-41367dfd31c1"
      },
      "source": [
        "Meh, that's not great. Let's maybe stretch out our figure a bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c433efb7-05fa-4c52-8acf-710604d0a3fa"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "fig.set_figwidth(12)\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(loc='upper right', frameon=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e98a0bec-501c-454a-b099-1b0c906334a6"
      },
      "source": [
        "Nice.\n",
        "\n",
        "Sometimes, it's tricky to place the legend within the border box of a plot. There can be a lot going on within the plot! In these cases, you can place the legend *outside* the axes. This is done via the *bbox_to_anchor* argument, which specifies where we want to anchor the legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caf4b920-c192-49fb-90c6-f013774a4fe8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(bbox_to_anchor=(0.5, -0.10))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8a02be8-35f7-4a5b-a3f2-d968bc5a5d0d"
      },
      "source": [
        "There are a few other parameters we can specify in the legend call as well. For example, the number of columns (*ncol*). If we set this to $2$ we would get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a057636-aa6c-4ad0-959b-104f0422748e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(bbox_to_anchor=(0.5, -0.10), ncol=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e11ce91-223b-4026-aa10-86874d8bd844"
      },
      "source": [
        "This doesn't look great. We can center it by setting \"loc = center\", which will center the bounding box around its location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f37bdeba-8ade-40c8-865d-4f8984922499"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(loc='center', bbox_to_anchor=(0.5, -0.10), ncol=2, shadow = True) #Note the shadow\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42622434-b6fa-48e4-a8fb-88d26e6b8171"
      },
      "source": [
        "Nice.\n",
        "\n",
        "Let's add a title to our legend, and make the font size larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b96bc0d0-d949-499b-a4b1-4c66f74b392b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(title='Functions', fontsize=12, title_fontsize=14, loc='center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67b3f4a-541b-4bf8-aa2d-258c97437925"
      },
      "source": [
        "Here, we changed the fort size for the legend and for the legend title. We can change all the font sizel by modifying the \"runtime configuration parameters\", or rcParams, specifically \"font.size\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d1fea76-4d7c-4251-b073-388cdd0f56a7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "x = np.arange(0,10,.1)\n",
        "y = np.sin(x)\n",
        "z = np.cos(x)\n",
        "\n",
        "plt.rcParams['font.size'] = '16'\n",
        "\n",
        "ax.plot(y, color = 'blue', label ='Sine wave')\n",
        "ax.plot(z, color = 'black', label='Cosine wave')\n",
        "leg = ax.legend(title='Functions', fontsize=12, title_fontsize=14, loc='center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fccda1c-6183-4776-a2fb-e5a83662996d"
      },
      "source": [
        "Alright, so this was a quick look at some of the basic plotting capabilities of matplotlib and pyplot. There's much, much more but just armed with these basics you can still create cool things - which is what you'll be doing in Assignment 2."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "0d0kk2pldg4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of most of the lecture notes I like to provide references for further reading. Please note these are generally here in case you're interested, but you're not required to check them out.\n",
        "\n",
        "Sometimes they may explore a topic in more depth, sometimes they might provide additional learning resources, and sometimes they might just be fun (I'll try to provide a link to a song each lecture).\n",
        "\n",
        "* [Introduction to NumPy](https://numpy.org/doc/stable/user/absolute_beginners.html)\n",
        "\n",
        "* [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
        "\n",
        "* [Pyplot tutorial](https://matplotlib.org/stable/tutorials/pyplot.html)\n",
        "\n",
        "* Song Of The Day (SOTD) - [Royals](https://youtu.be/nlcIKh6sBtcsi=duDiNtjAzRyh5OUJ) by Lorde\n",
        "\n",
        "* Why did I use $24601$ as a random seed? It's a reference to [this](https://youtu.be/rEi9wgbob-0?si=yHM-24r4yH8gR3S-)."
      ],
      "metadata": {
        "id": "ZeYCZ3wVeE5f"
      }
    }
  ]
}